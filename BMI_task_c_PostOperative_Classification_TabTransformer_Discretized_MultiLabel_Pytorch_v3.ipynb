{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9e7a689-1442-4570-88d2-016123920037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from torchmetrics import AUROC\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import gc, sys, random, warnings\n",
    "gc.enable()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f4b70f-515b-4ffc-b7cd-f06c5305fca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchmetrics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197204b8-b2b5-4f8b-9834-723d887dc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b85a33c-a00b-4c89-bfc8-4bc14658a511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b30d72f-ef70-4568-9b37-90afb6a9a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "seed_all(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220d653c-eba9-469d-be4e-f073f84b2e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738, 39)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "path = './Backup_Regression/'\n",
    "name = 'Predictions_Option_1.xlsx'\n",
    "\n",
    "data = pd.read_excel(path+name)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2744f0ac-3e74-405b-a64a-e5f450da8cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Complication after surgery (1 = Anastomotic leakage\\n2 = Sleeve leak\\n3 = Intussusception after Roux-en-Y gastric bypass\\n4 = Mesenteric internal hernia after Roux-en-Y gastric bypass\\n5 = Internal hernia through Peterson`s defect after Roux-en-Y gastric bypass\\n6 = Hiatal hernia\\n7 = Gastro Esophageal Reflux Disease (GERD)\\n8 = Amastomotic Ulcer\\n9 = Anastomotic stricture\\n10 = Hemorrhage\\n11 = No Complication)', 'Body mass index 3 months after surgery', 'Body mass index 6 months after surgery', 'Body mass index 12 months after surgery', 'Body mass index 18 months after surgery', 'Body mass index 2 years after surgery', 'Body mass index 3 years after surgery', 'Body mass index 4 years after surgery', 'Body mass index 5 years after surgery']\n",
      "Dropping 11 columns...\n",
      "(738, 28)\n",
      "(738, 28) (738, 28) (0, 28)\n",
      "(590, 20) (590, 8) (148, 20) (148, 8)\n",
      "(590, 20) (590, 8) (148, 20)\n"
     ]
    }
   ],
   "source": [
    "# bmi_original_columns = [col for col in data.columns if 'Body mass index' in col and 'after surgery' in col and 'predicted' not in col]\n",
    "post_surgery_columns = [col for col in data.columns if 'after surgery' in col and 'predicted' not in col and 'Diabetes Mellitus' not in col]\n",
    "print(post_surgery_columns)\n",
    "\n",
    "# Drop the bmi post surgery (original) columns, since a lot of them have mising values\n",
    "cols_to_drop = post_surgery_columns + ['record_id','redcap_data_access_group']\n",
    "print(f'Dropping {len(cols_to_drop)} columns...')\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "#print('Adding a sample weight column..')\n",
    "#data['sample_weight'] = 1\n",
    "print(data.shape)\n",
    "\n",
    "data.columns = [col.strip() for col in data.columns]\n",
    "\n",
    "data4 = data.copy()\n",
    "data5 = data4[(data4['Diabetes Mellitus 3 months after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 6 months after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 12 months after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 18 months after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 2 years after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 3 years after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 4 years after surgery (1 = Yes\\n2 = No)'].isnull() == False)&(data4['Diabetes Mellitus 5 years after surgery (1 = Yes\\n2 = No)'].isnull() == False)].copy()\n",
    "data6 = data4.loc[~data4.index.isin(data5.index.tolist())]\n",
    "print(data4.shape, data5.shape, data6.shape)\n",
    "\n",
    "# Split the data in train and validation and then, for train data, perform the KFold Cross Validation\n",
    "target_columns = ['Diabetes Mellitus 3 months after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 6 months after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 12 months after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 18 months after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 2 years after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 3 years after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 4 years after surgery (1 = Yes\\n2 = No)',\n",
    "                 'Diabetes Mellitus 5 years after surgery (1 = Yes\\n2 = No)']\n",
    "\n",
    "Y = data5[target_columns].copy()\n",
    "# Replace 2's in Y with 0's\n",
    "Y = Y.replace(2,0)\n",
    "X = data5.drop(columns = target_columns).copy()\n",
    "X1 , X_val , Y1 , Y_val = train_test_split(X ,\n",
    "                                           Y,\n",
    "                                           test_size = 0.2,\n",
    "                                           random_state = 1234)\n",
    "\n",
    "print(X1.shape, Y1.shape, X_val.shape, Y_val.shape)\n",
    "\n",
    "# train_data = pd.concat([X1,Y1],axis=1)\n",
    "# test_data = pd.concat([X_val,Y_val],axis=1)\n",
    "# print(train_data.shape, test_data.shape)\n",
    "\n",
    "\n",
    "target_df = Y1\n",
    "train_df = X1\n",
    "#train_df['target'] = target_df.iloc[:,:1]\n",
    "test_df = X_val\n",
    "print(train_df.shape, target_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25630e5-2d92-425b-a9eb-45709c384dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'sex (1=Female\\n2=Male)',\n",
    "    'American Society of Anesthesiologists (ASA) Score (1 = ASA 1: healthy person\\n2 = ASA 2: mild systemic disease\\n3 = ASA 3: severe systemic disease\\n4 =ASA 4: severe systemic disease that is a constant threat to life\\n5 = ASA 5: a moribund person who is not expected to survive without the operation)',\n",
    "    'Diabetes mellitus type II preoperative (1 = yes\\n2 = No)',\n",
    "    'Antidiabetic drugs preoperativ (1 = Orale Antidiabetic drugs\\n2 = Insulin\\n3 = No therapy)',\n",
    "    'Obstructive sleep apnea syndrome (OSAS) preoperative  (1 = yes\\n2 = No)',\n",
    "    'surgery (1 = LSG (Laparoscopic Sleeve Gastrectomy)\\n2 = RYGB (Roux en-Y Gastric Bypass)\\n3 = SADI (single anastomosis duodeno-ileal bypass)\\n4 = BPD-DS (Biliopancreatic diversion with duodenal switch)\\n5 = OAGB (One-anastomosis Gastric Bypass)',\n",
    "    'Conversion from gastric sleeve to gastric bypass (1 = Yes\\n2 = No\\n3 = Not available)',\n",
    "    \"Closure of Petersen's space (1 = Yes\\n2 = No\\n3 = Not available)\",\n",
    "    'Closure of the jejunojejunostomy defect (1 = Yes\\n2 = No\\n3 = Not available)'\n",
    "]\n",
    "\n",
    "cont_cols = list(set(train_df.columns)-set(cat_cols))\n",
    "\n",
    "train_df = train_df[cont_cols+cat_cols]\n",
    "test_df = test_df[cont_cols+cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb517a4-f3b0-493e-94c8-568b94f92e21",
   "metadata": {},
   "source": [
    "##### Converting numerical features into Normal Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfa429f-4264-4e04-afc8-00f5d31e677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = train_df.copy(), test_df.copy()\n",
    "for col in cont_cols:\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_scaled[col].values)\n",
    "    vec_len_test = len(test_scaled[col].values)\n",
    "    raw_vec = train_scaled[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_scaled[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_scaled[col] = transformer.transform(test_scaled[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3b55e8-cd55-4435-85fd-532d8059cb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(train_df); del (test_df); gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ded87-60cb-41a1-9555-5f6b1e6d45ba",
   "metadata": {},
   "source": [
    "##### Discretizing Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fae5949-fead-433c-9b7c-e7694dfdb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = KBinsDiscretizer(n_bins=50, encode='ordinal',strategy='uniform')\n",
    "train_scaled[cont_cols] = disc.fit_transform(train_scaled[cont_cols])\n",
    "test_scaled[cont_cols] = disc.transform(test_scaled[cont_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9214e63-59b3-4425-b406-2426ea2480f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target_df.values\n",
    "train_scaled = train_scaled.values\n",
    "test_scaled = test_scaled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759768c-1ee2-4a2f-b5be-dc91f11602fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([0.16, 0.16, 0.25, 0.25, 0.083, 0.083])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62a988ac-7a54-440f-b7fc-7467aa5a389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56e127d2-ea6f-4e84-9195-487c3665d7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02040816326530612,\n",
       " 0.019230769230769232,\n",
       " 0.012345679012345678,\n",
       " 0.023255813953488372,\n",
       " 0.01282051282051282,\n",
       " 0.022727272727272728,\n",
       " 0.025,\n",
       " 0.024390243902439025]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(1/y_train.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e119b63d-0a89-4d41-8465-a089b0102140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590, 8), (590, 20), (148, 20))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, train_scaled.shape, test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5e000-a074-46f2-8b0b-ffafaec505cb",
   "metadata": {},
   "source": [
    "##### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087f302f-c290-4fa4-9cb9-17fbb96c5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b3ad693-f98e-452b-9808-41be7cd66a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.001, verbose = None):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score: #  + self.delta\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            if self.verbose:\n",
    "                print('Validation score improved ({:.4f} --> {:.4f}). Saving model!'.format(self.val_score, epoch_score))\n",
    "                \n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e95e8f5-8811-4edc-94bb-15ce0a55df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated to pass a contant cont value in this version\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, cat, target = None):\n",
    "        super().__init__()\n",
    "        self.cat = cat\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cat = self.cat[idx]\n",
    "        \n",
    "        _dict = {'cont': torch.ones(1),\n",
    "                 'cat': torch.LongTensor(cat)}\n",
    "        \n",
    "        if self.target is not None:\n",
    "            target = self.target[idx]\n",
    "            _dict.update({'target': torch.tensor(target, dtype = torch.float)})\n",
    "        \n",
    "        return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18965c1c-95e8-4b9b-9539-622a031222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, loss_fn, opt, scheduler = None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.opt = opt\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "    def fit_one_epoch(self, dl):\n",
    "        self.model.train()\n",
    "        losses = AverageMeter()\n",
    "        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n",
    "        \n",
    "        for bi, d in prog_bar:\n",
    "            cont = d[\"cont\"].to(self.device)\n",
    "            cat = d['cat'].to(self.device)\n",
    "            target = d['target'].to(self.device)\n",
    "            \n",
    "            out = self.model(cat, cont)\n",
    "            loss = self.loss_fn(out.squeeze(-1), target)\n",
    "            prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n",
    "            losses.update(loss.item(), cont.size(0))\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            \n",
    "            if self.scheduler: \n",
    "                self.scheduler.step()\n",
    "                    \n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "    def eval_one_epoch(self, dl, **kwargs):\n",
    "        self.model.eval()\n",
    "        losses = AverageMeter()\n",
    "        metric = AUROC(task='binary')\n",
    "        prog_bar = tqdm(enumerate(dl), total = len(dl), file=sys.stdout, leave = False)\n",
    "        \n",
    "        for bi, d in prog_bar:  \n",
    "            cont = d[\"cont\"].to(self.device)\n",
    "            cat = d['cat'].to(self.device)\n",
    "            target = d['target'].to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out = self.model(cat, cont)\n",
    "                #print('Out :', out)\n",
    "                loss = self.loss_fn(out.squeeze(-1), target)\n",
    "                if metric:\n",
    "                    auroc = metric(out.squeeze(-1), target.int())\n",
    "                \n",
    "                losses.update(loss.item(), cont.size(0))\n",
    "        auroc = metric.compute()\n",
    "        print(f\"F{kwargs['fold']} E{str(kwargs['epoch']):2s}\"\\\n",
    "              f\"  Valid Loss: {losses.avg:.4f}  AUROC Score: {auroc:.4f}\")\n",
    "        return auroc.cpu() if metric else losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfa1df-86b9-4a97-92a6-b68b7a500af5",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe14b1-d454-452e-9144-cb2d4fb30f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70f1964a-885a-470e-b1f4-3fb0dd81cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    bs = 64\n",
    "    n_splits = 5\n",
    "    seed = 2021\n",
    "    epochs = 3\n",
    "    lr = 2e-5\n",
    "    checkpoint = lambda fold: f'full_cat_{fold}.pt'\n",
    "    \n",
    "kfold = KFold(n_splits = cfg.n_splits, \n",
    "                        random_state = cfg.seed, \n",
    "                        shuffle = True)\n",
    "splits = [*kfold.split(X = train_scaled, y = y_train[:,:1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54ca34b-7897-4b93-b5b2-5e390bfecd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,   4,   5,   7,   9,  10,  11,  12,  15,  16,  17,  18,  19,\n",
       "         20,  22,  23,  25,  26,  27,  29,  30,  31,  33,  35,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  51,  53,\n",
       "         54,  55,  56,  57,  58,  59,  61,  62,  63,  64,  65,  66,  67,\n",
       "         68,  69,  70,  71,  72,  74,  75,  77,  78,  79,  80,  81,  82,\n",
       "         83,  84,  85,  86,  87,  89,  91,  92,  93,  94,  95,  96,  97,\n",
       "         99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114,\n",
       "        116, 117, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131,\n",
       "        132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145,\n",
       "        146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160,\n",
       "        161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
       "        175, 176, 178, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205,\n",
       "        206, 208, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "        223, 224, 225, 228, 229, 230, 231, 233, 234, 236, 237, 238, 239,\n",
       "        240, 241, 242, 243, 244, 245, 246, 249, 250, 251, 253, 254, 255,\n",
       "        256, 257, 258, 259, 261, 263, 264, 266, 267, 268, 269, 270, 271,\n",
       "        272, 273, 275, 276, 277, 279, 280, 281, 282, 283, 286, 287, 288,\n",
       "        289, 290, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 305,\n",
       "        306, 307, 308, 310, 311, 313, 314, 315, 316, 317, 318, 320, 321,\n",
       "        322, 323, 325, 326, 327, 328, 329, 330, 331, 333, 337, 339, 341,\n",
       "        342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355,\n",
       "        356, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
       "        371, 372, 373, 375, 377, 379, 380, 381, 382, 383, 385, 386, 387,\n",
       "        388, 389, 390, 393, 396, 397, 398, 400, 402, 403, 404, 405, 406,\n",
       "        407, 408, 409, 410, 411, 412, 413, 416, 417, 418, 419, 420, 421,\n",
       "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435,\n",
       "        436, 438, 439, 440, 441, 442, 444, 446, 447, 448, 449, 451, 452,\n",
       "        453, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 466, 468,\n",
       "        469, 470, 471, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482,\n",
       "        483, 484, 486, 487, 488, 489, 492, 493, 494, 495, 496, 498, 499,\n",
       "        500, 502, 503, 505, 506, 507, 508, 509, 510, 511, 513, 515, 516,\n",
       "        517, 518, 521, 522, 523, 525, 527, 528, 529, 530, 531, 533, 536,\n",
       "        537, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 551, 552,\n",
       "        553, 554, 555, 558, 559, 560, 561, 563, 564, 566, 567, 568, 569,\n",
       "        570, 571, 572, 573, 574, 575, 576, 577, 581, 582, 583, 584, 585,\n",
       "        586, 587, 588, 589]),\n",
       " array([  0,   1,   3,   6,   8,  13,  14,  21,  24,  28,  32,  34,  36,\n",
       "         46,  52,  60,  73,  76,  88,  90,  98, 103, 106, 111, 115, 118,\n",
       "        124, 125, 141, 147, 158, 165, 177, 179, 182, 187, 200, 207, 209,\n",
       "        210, 214, 226, 227, 232, 235, 247, 248, 252, 260, 262, 265, 274,\n",
       "        278, 284, 285, 291, 292, 303, 304, 309, 312, 319, 324, 332, 334,\n",
       "        335, 336, 338, 340, 353, 357, 358, 374, 376, 378, 384, 391, 392,\n",
       "        394, 395, 399, 401, 414, 415, 432, 437, 443, 445, 450, 454, 465,\n",
       "        467, 474, 485, 490, 491, 497, 501, 504, 512, 514, 519, 520, 524,\n",
       "        526, 532, 534, 535, 538, 548, 550, 556, 557, 562, 565, 578, 579,\n",
       "        580]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edfea86a-90be-433f-89cb-12cafa70265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols), len(cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f9fb9d0-e4b0-4e4e-82a8-87c69a9f18a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0,0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7254f402-4985-4cf5-87c5-2680d1735d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_cfg = {\n",
    "    'categories' : [50]*11 + [2, 5, 2, 3, 2, 5, 3, 3, 3],           # iterable with the number of unique values for categoric feature\n",
    "    #'categories' : [2, 5, 2, 3, 2, 5, 3, 3, 3],           # iterable with the number of unique values for categoric feature\n",
    "    'num_continuous' : 1,                       # continuous dimensions in data\n",
    "    'dim' : 32,                                 # hidden dim, paper set at 32\n",
    "    'dim_out' : 8,                              # binary prediction\n",
    "    'depth' : 3,                                # depth, paper recommended 6\n",
    "    'heads' : 6,                                # heads, paper recommends 8\n",
    "    'attn_dropout' : 0.1,                       # post-attention dropout\n",
    "    'ff_dropout' : 0.1,                         # feed forward dropout\n",
    "    'mlp_hidden_mults' : (4, 2),                # relative multiples of each hidden dimension of the last mlp to logits\n",
    "    'mlp_act' : nn.GELU(),                      # activation for final mlp, defaults to relu\n",
    "    'continuous_mean_std' : torch.randn(1, 2)   # normalize the continuous values before layer norm (optional)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "707de252-fbeb-4097-9421-eb31e120e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50e37505-a98c-4718-b61c-208698012525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(fold):\n",
    "    train_idx, valid_idx = splits[fold]\n",
    "    \n",
    "    _xtr, _ytr = train_scaled[train_idx], y_train[train_idx]\n",
    "    _xval, _yval = train_scaled[valid_idx], y_train[valid_idx]\n",
    "    \n",
    "    train_ds = TabDataset(cat = _xtr, target = _ytr)\n",
    "    valid_ds = TabDataset(cat = _xval, target = _yval)\n",
    "                          \n",
    "    train_dl = DataLoader(train_ds, batch_size = cfg.bs, shuffle = True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size = cfg.bs, shuffle = False)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53b60d11-eb6a-403c-89ff-820d6b68ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(fold, epochs = 20):\n",
    "    train_dl, valid_dl = create_dataloaders(fold)\n",
    "    es = EarlyStopping(patience = 7, mode=\"max\", verbose = False)\n",
    "    \n",
    "    model = TabTransformer(**transformer_cfg).to(device)\n",
    "    \n",
    "    opt = torch.optim.AdamW(model.parameters(), lr = cfg.lr)\n",
    "\n",
    "    trainer = Trainer(model, \n",
    "                      device, \n",
    "                      loss_fn=nn.BCEWithLogitsLoss(),\n",
    "                      opt = opt,\n",
    "                      scheduler = None,\n",
    "                     )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        trainer.fit_one_epoch(train_dl)\n",
    "        valid_loss = trainer.eval_one_epoch(valid_dl, fold = fold, epoch = epoch)\n",
    "        \n",
    "        es(valid_loss, trainer.model, model_path = cfg.checkpoint(fold))       \n",
    "        if es.early_stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e090667-828d-41cb-950a-805ef7cf3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0 E0   Valid Loss: 0.6051  AUROC Score: 0.7529                                                                        \n",
      "F0 E1   Valid Loss: 0.5275  AUROC Score: 0.8288                                                                        \n",
      "F0 E2   Valid Loss: 0.4547  AUROC Score: 0.8623                                                                        \n",
      "F1 E0   Valid Loss: 0.5951  AUROC Score: 0.7106                                                                        \n",
      "F1 E1   Valid Loss: 0.5104  AUROC Score: 0.8264                                                                        \n",
      "F1 E2   Valid Loss: 0.4301  AUROC Score: 0.8837                                                                        \n",
      "F2 E0   Valid Loss: 0.6017  AUROC Score: 0.7191                                                                        \n",
      "F2 E1   Valid Loss: 0.5144  AUROC Score: 0.8452                                                                        \n",
      "F2 E2   Valid Loss: 0.4307  AUROC Score: 0.8940                                                                        \n",
      "F3 E0   Valid Loss: 0.5815  AUROC Score: 0.7565                                                                        \n",
      "F3 E1   Valid Loss: 0.4851  AUROC Score: 0.8431                                                                        \n",
      "F3 E2   Valid Loss: 0.3950  AUROC Score: 0.8689                                                                        \n",
      "F4 E0   Valid Loss: 0.5918  AUROC Score: 0.7254                                                                        \n",
      "F4 E1   Valid Loss: 0.5034  AUROC Score: 0.8367                                                                        \n",
      "F4 E2   Valid Loss: 0.4218  AUROC Score: 0.8843                                                                        \n"
     ]
    }
   ],
   "source": [
    "for fold in range(cfg.n_splits):\n",
    "    train_fold(fold, cfg.epochs)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c77c0-abda-41c1-b2b6-7552cf887287",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79a5575a-716f-4da8-85db-5aa88e5e3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.zeros(len(test_scaled), 8).to(device)\n",
    "test_ds = TabDataset(cat = test_scaled)\n",
    "test_dl = DataLoader(test_ds, batch_size = cfg.bs, shuffle = False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fold in range(cfg.n_splits):\n",
    "        preds = []\n",
    "        model = TabTransformer(**transformer_cfg).to(device)\n",
    "        state_dict = cfg.checkpoint(fold)\n",
    "        model.load_state_dict(torch.load(state_dict))\n",
    "        model.eval()\n",
    "        \n",
    "        for d in test_dl:\n",
    "            cont = d[\"cont\"].to(device)\n",
    "            cat = d['cat'].to(device)\n",
    "            out = model(cat, cont)\n",
    "            preds.append(out)\n",
    "            \n",
    "        preds = torch.vstack(preds)\n",
    "        y_pred += preds / cfg.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d57f2cc1-ea26-4f43-9ba9-1a7f2718f44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([148, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a27393b-0c09-44ce-8980-6eb0e916a25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([148, 8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(Y_val.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fc5e7b5-5c83-4391-b25e-acfb8bf120cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7919, -0.7902, -0.7587,  ..., -0.8591, -0.8288, -0.8651],\n",
       "        [-0.7902, -0.8099, -0.7678,  ..., -0.9030, -0.8288, -0.8148],\n",
       "        [-0.6264, -0.6321, -0.5157,  ..., -0.7070, -0.6685, -0.7639],\n",
       "        ...,\n",
       "        [-0.7343, -0.7299, -0.6506,  ..., -0.8169, -0.8064, -0.7835],\n",
       "        [-0.8713, -0.8673, -0.8537,  ..., -0.9560, -0.9312, -0.9130],\n",
       "        [-0.6894, -0.7314, -0.7007,  ..., -0.8131, -0.7698, -0.7483]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02b26ba9-8ea4-4ed6-8cd0-62895b3fad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8e1fe97-e20d-4551-847d-2cd02c05452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4377)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn=nn.BCEWithLogitsLoss()\n",
    "loss_fn(y_pred, torch.tensor(Y_val.values, dtype=torch.float32))\n",
    "# nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60b13890-58b7-4d9c-a2e8-c721cb94b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "y_hat = sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "361b90a0-801c-479d-a01e-760c1aee8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.310236</td>\n",
       "      <td>0.308740</td>\n",
       "      <td>0.320185</td>\n",
       "      <td>0.300516</td>\n",
       "      <td>0.323239</td>\n",
       "      <td>0.291340</td>\n",
       "      <td>0.299247</td>\n",
       "      <td>0.299631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>0.020792</td>\n",
       "      <td>0.017816</td>\n",
       "      <td>0.016359</td>\n",
       "      <td>0.016108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.276965</td>\n",
       "      <td>0.282198</td>\n",
       "      <td>0.283236</td>\n",
       "      <td>0.278874</td>\n",
       "      <td>0.287528</td>\n",
       "      <td>0.263196</td>\n",
       "      <td>0.268981</td>\n",
       "      <td>0.272665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.297601</td>\n",
       "      <td>0.294224</td>\n",
       "      <td>0.303911</td>\n",
       "      <td>0.289724</td>\n",
       "      <td>0.309635</td>\n",
       "      <td>0.278355</td>\n",
       "      <td>0.287337</td>\n",
       "      <td>0.288586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.305068</td>\n",
       "      <td>0.303543</td>\n",
       "      <td>0.313356</td>\n",
       "      <td>0.296954</td>\n",
       "      <td>0.316957</td>\n",
       "      <td>0.287084</td>\n",
       "      <td>0.295840</td>\n",
       "      <td>0.296519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.318989</td>\n",
       "      <td>0.319847</td>\n",
       "      <td>0.329614</td>\n",
       "      <td>0.307485</td>\n",
       "      <td>0.330656</td>\n",
       "      <td>0.299967</td>\n",
       "      <td>0.308041</td>\n",
       "      <td>0.309522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.365376</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.395372</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.387490</td>\n",
       "      <td>0.350941</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>0.347511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  148.000000  148.000000  148.000000  148.000000  148.000000  148.000000   \n",
       "mean     0.310236    0.308740    0.320185    0.300516    0.323239    0.291340   \n",
       "std      0.018310    0.018796    0.022429    0.015660    0.020792    0.017816   \n",
       "min      0.276965    0.282198    0.283236    0.278874    0.287528    0.263196   \n",
       "25%      0.297601    0.294224    0.303911    0.289724    0.309635    0.278355   \n",
       "50%      0.305068    0.303543    0.313356    0.296954    0.316957    0.287084   \n",
       "75%      0.318989    0.319847    0.329614    0.307485    0.330656    0.299967   \n",
       "max      0.365376    0.367900    0.395372    0.356913    0.387490    0.350941   \n",
       "\n",
       "                6           7  \n",
       "count  148.000000  148.000000  \n",
       "mean     0.299247    0.299631  \n",
       "std      0.016359    0.016108  \n",
       "min      0.268981    0.272665  \n",
       "25%      0.287337    0.288586  \n",
       "50%      0.295840    0.296519  \n",
       "75%      0.308041    0.309522  \n",
       "max      0.349027    0.347511  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_hat).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2267e0f7-3ac7-4669-bd87-df7fea5cd601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7919, -0.7902, -0.7587, -0.8137, -0.7485, -0.8591, -0.8288, -0.8651])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be5eca82-f2a1-40d1-88d1-ed81cdb3d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7919, -0.7902, -0.7587, -0.8137, -0.7485, -0.8591, -0.8288, -0.8651])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5033beb-7a82-4d44-98f8-5da6293bf25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb0474e3-6156-48bd-99c6-309b628ff662",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[0,1,0,1,0,0],[0,1,0,1,0,1]], dtype=torch.float32)\n",
    "output = torch.tensor([[0.2,0.9,0.2,0.8,0.3,0.2],[0.1,0.8,0.2,0.9,0.3,0.7]])\n",
    "weights = torch.tensor([0.16, 0.16, 0.25, 0.25, 0.083, 0.083])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c534ed7-7808-4906-90ed-fb4dbc3ecda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da956580-d0f9-4009-b447-4e2b37eaa474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7981, 0.3412, 0.7981, 0.3711, 0.8544, 0.7981],\n",
       "        [0.7444, 0.3711, 0.7981, 0.3412, 0.8544, 0.4032]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5780b5b3-45b1-427e-9916-8fcd37521851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7981, 0.3412, 0.7981, 0.3711, 0.8544, 0.7981],\n",
       "        [0.7444, 0.3711, 0.7981, 0.3412, 0.8544, 0.4032]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18b8a5eb-abea-4d86-a940-4065c036e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (loss * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75589e2e-584f-45d2-aa20-729a00832382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0983)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "032b3e15-ceac-4723-a5c5-2f5b8b166a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0983)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aafb65-d328-4114-a7f8-06b2539db44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
